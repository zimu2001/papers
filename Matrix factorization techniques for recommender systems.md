Matrix factorization techniques for recommender systems

[原文](https://ieeexplore.ieee.org/abstract/document/5197422)

#### 0

在此之前，介绍两种经典的协同过滤推荐方法。

一是邻域方法（neighborhood methods），如下图所示。是一种基于user的CF。

![image-20240916163047462](./Matrix factorization techniques for recommender systems/image-20240916163047462.png)

joe喜欢左边的三部电影。为了对他进行预测，系统会找到也喜欢这些电影的相似用户，然后确定他们喜欢哪些其他电影。在这种情况下，三个人都喜欢《拯救大兵瑞恩》，所以这是第一个推荐。其中两人喜欢《沙丘》，所以这是下一个，依此类推。

二是隐因子模型（latent factor models）

其试图通过将物品和用户描述为基于评分模式推断出的 20 到 100 个因子来解释评分。下图是一个例子。

![image-20240916163828105](./Matrix factorization techniques for recommender systems/image-20240916163828105.png)

考虑两个假设的维度，分别是女性导向与男性导向、严肃导向与逃避现实导向。该图显示了几部知名电影和一些虚构用户可能落在这两个维度上的位置。

对于此模型，用户对电影的预测评分相对于电影的平均评分将等于图表上电影和用户位置的点积。例如我们会假定 Gus 喜欢《阿呆与阿瓜》，讨厌《紫色》，并对《勇敢的心》评价为一般。请注意，某些电影（例如《十一罗汉》）和用户（例如戴夫）在这两个维度上会被描述为相当中立。

#### 矩阵分解方法

隐因子的成功是基于矩阵分解方法的，在其基本形式中，矩阵分解通过从项目评分模式推断出的因子向量来表征项目和用户。高度一致的user和item因子会导致推荐的发生。

推荐系统依赖于不同类型的输入数据，这些数据通常放置在一个矩阵中，其中一个维度代表用户，另一个维度代表感兴趣的项目。

最方便的数据是高质量的显式反馈，其中包括用户关于他们对产品的兴趣的显式输入。例如，Netflix 收集电影的星级，TiVo 用户通过按“拇指向上”和“拇指向下”按钮来表明他们对电视节目的偏好。我们将明确的用户反馈称为**评级（ratings）**。通常，显式反馈包含稀疏矩阵，因为任何单个用户可能只对一小部分可能的项目进行了评分。

矩阵分解的优点之一是它允许合并附加信息。当无法获得显式反馈时，推荐系统可以使用隐式反馈（implict feedback）来推断用户偏好，隐式反馈通过观察用户行为（包括购买历史记录、浏览历史记录、搜索模式甚至鼠标移动）来间接反映意见。隐式反馈通常表示事件的存在或不存在，因此它通常由密集填充的矩阵表示。

##### 基本模型

矩阵分解模型将用户和项目映射到维度为 f 的联合潜在因子空间，以便将用户-项目交互建模为该空间中的内积。每个item都与一个向量关联  qi ∈ R^f，每个user与一个向量pu ∈ R^f。 对于给定的项目 i，qi 的元素衡量该项目拥有这些因素（正面或负面）的程度。对于给定的用户 u，pu 的元素衡量用户对相应因素（同样是正面或负面）较高的项目的兴趣程度。得到的点积 qi T pu 捕获了用户 u 和项目 i 之间的交互——用户对项目特征的总体兴趣。这近似于用户 u 对项目 i 的评分，用 rui 表示，从而得出估计

![image-20240916165921682](./Matrix factorization techniques for recommender systems/image-20240916165921682.png)

主要的难点就是如何得到映射，完成此映射后，可以使用上述公式轻松估计用户对任何项目的评分。

这种模型与奇异值分解（SVD）密切相关，奇异值分解是一种用于识别信息检索中潜在语义因素的成熟技术。在协同过滤领域应用 SVD 需要考虑用户-项目评分矩阵。由于用户-项目评分矩阵的稀疏性导致大量缺失值，这通常会带来困难。当矩阵知识不完整时，传统的 SVD 是不确定的。此外，只处理相对较少的已知条目很容易出现过度拟合。

早期的系统依靠插补来填充缺失的评级并使评级矩阵变得密集。然而，插补可能非常昂贵，因为它会显着增加数据量。此外，不准确的估算可能会严重扭曲数据。因此，最近的作品3-6建议仅直接对观察到的评级进行建模，同时通过正则化模型避免过度拟合。

为了学习因子向量（pu 和 qi），系统最小化已知评级集的正则平方误差：

![image-20240916210234208](./Matrix factorization techniques for recommender systems/image-20240916210234208.png)

ru 是实际评分 ， κ 是已知 rui 的 (u,i) 对的集合（训练集）。常数 λ 控制正则化的程度，通常由交叉验证确定。 Ruslan Salakhutdinov 和 Andriy Mnih 的“概率矩阵分解”7 为正则化提供了概率基础。

##### 模型的学习

对于公式（2）使其最小化。可以使用SGD和交替最小二乘法（ALS）

###### stochastic gradient descent

对于每个给定的训练案例，系统预测 rui 并计算相关的预测误差

![image-20240916210702029](./Matrix factorization techniques for recommender systems/image-20240916210702029.png)

然后，它在梯度的相反方向上按与 /gama 成比例的幅度修改参数，产生：

![image-20240916210734940](./Matrix factorization techniques for recommender systems/image-20240916210734940.png)

其易于实施，速度更快

###### alternating least squares

公式（2）的变量是未知的，不是凸函数，即不能通过梯度下降获得最优解。

ALS的方法是，固定其中的一个变量，问题可以得到解决——交替对 qi 和 pu 使用最小二乘法，直至收敛。

具体来说，比如固定 qi ，公式（2）变为关于 pu 的二次函数，并可以通过求导获得其最优解。

##### adding bias

